#summary One-sentence summary of this page.

= HLFS 用户手册 =

== 准备动作 ==
基本环境要求：
 * 32、64位Linux系统操作系统（我是在ubuntu10.4和Centos上进行开发的）
 * 2G  以上内存
===Hadoop 安装===
   hlfs需要使用hadoop hdfs的append功能实现log追加操作，因此我们需要选择hadoop-0.20-append或者cloudera的ch3版本（默认支持了append功能，不用再配置 dfs.support.append=true了，如果使用其他版本一定要打开该功能），关于hadoop append问题域的分析请见http://www.cloudera.com/blog/2009/07/file-appends-in-hdfs.<br>
   我们建议使用cloudera的ch3，安装方式参见  https://ccp.cloudera.com/display/CDHDOC/CDH3+Installation
===Xen 安装===   
   我们使用xen中的tapdisk2模式加载hlfs磁盘，因此需要使用xen4.0之上版本（如果低版本xen需要打上tapdisk2的patch)。因此我们建议使用xen4.1.x 。 对于dom0内核版本，我们建议不要用2.6.18的老内核，使用当前2.6.32以上的内核比较可靠。<br>
   关于xen的安装，网上资料很多。 也可以参见我们download中提供的资料http://code.google.com/p/cloudxy/downloads/detail?name=xen_guide.pdf
   

== HLFS START UP ==
 === 获取hlfs代码和相关依赖库 ===
   在终端键入'svn checkout http://cloudxy.googlecode.com/svn/trunk/hlfs/  hlfs'
 === 编译hlfs ===
   # 安装cmake;安装glib库;安装java。
   # 修改在hlfs/src/CMakeLists.txt中配置你正确的java目录 'SET(JAVA_HOME   /usr/lib/jvm/java-6-sun)'。
   # 生成makefile:cd hlfs/build；cmake ../src（生成makefile)
   # make {all | libhlfs | tools | test} 
      * all: 生成所有库和工具
      * libhlfs: 生成hlfs动态库
      * tools: 生成所有工具
----
   ** _src hlfs库源代码目录_
   ** _nbd-2.9.15 修改后的nbd-server/nbd-client源代码目录_
   ** _3part 第三方库，目前包含hadoop相关;log库_
   ** _output 编译后的生成库和工具所在目录_
----
 === 测试hlfs ===
 为了方便调试目的，hlfs实现中支持了本地测试（不需要hadoop hdfs),我们称为local模式。我们首先用local模式测试
   * 编译hlfs - cd hlfs/build;cmake ../src/;make all
   * local模式下格式化hlfs文件系统 
       # mkdir /tmp/testenv //需要一个类似workshop的工作环境
       # ./output/bin/mkfs.hlfs -u local:///tmp/testenv/testfs -b 8192 -s 67108864 -m 1024 (-b是数据块大小，单位是byte， -s是段文件大小，单位是byte， -m 是虚拟磁盘的最大容量,单位是M) 
   * 编译测试用例 - cd test;camke .;make 
   * 执行测试用例 - ./test -u local:///tmp/testenv/testfs 
-----
    * _格式化目的是写入原数据到superblock中，这些元数据描述了该hlfs的属性信息；当格式化完成后，你会在/tmp/testenv目录下，发现testfs目录，再其下发现superblock文件，查看该文件，会发现块大小、段大小、容量限制等该hlfs的属性信息_
    * _执行完毕后，会在/tmp/testenv/testfs下发现生成的段文件_
----
 如果你已经安装hadoop hdfs，并且已经启动，则可以测试hdfs模式，测试方式
  * 编译hlfs - cd hlfs/build;cmake ../src/;make all
  * hdfs 模式下格式化hlfs文件系统 (我们以伪分布模式执行）
       # hadoop fs -mkdir hdfs:///tmp/testenv
       # ./output/bin/mkfs.hlfs -u hdfs:///tmp/testenv/testfs -b 8192 -s 67108864 -m 1024 　
  * 编译测试用例 - cd test;camke .;make 
  * 执行测试用例 - ./test -u hdfs:///tmp/testenv/testfs   
----
  * _可见local模式和hdfs模式只是uri都head不同而已_
  * _执行hadoop fs -ls /tmp/testenv/testfs命令你可看到类似local模式下的各种文件_
hadoop shell 命令请见  http://hadoop.apache.org/common/docs/r0.17.2/hdfs_user_guide.html
----

== HLFS 存储虚拟机镜像 == 
如果上述步骤成功，那么可以开始尝试EBS了。使用HLFS作为虚拟机的数据盘，甚至可以做系统安装盘。
   * 添加hlfs driver for tapdisk2 - patch?
   * 编译，安装，激活
   * 测试- 
   * 作为数据盘启动

== HLFS 用作虚拟网盘 == 
  * 编译nbd  
     # cd nbd-2.9.15/build;
     # cmake ../;
     # make (编译后内容在nbd-2.9.15/outpub下）
   * 加载模块 - sudo modprobe nbd (nbd服务需要一个对应的内核模块，这个模块一般没有被默认加载）
   * 启动nbd server - ./nbd-2.9.15/output/bin/nbd-server 20000 (20000是服务端口号）    
   * 格式化hlfs 
     mkfs.hlfs -u local:///tmp/testenv/testfs -b 8192 -s 67108864 -m 1024或<br>  mkfs.hlfs -u hdfs:///tmp/testenv/testfs -b 8192 -s 67108864 -m 1024
   * 挂接nbd设备 - ./nbd-2.9.15/output/bin/nbd-client bs=512 127.0.0.1 20000  local:///tmp/testenv/testfs /dev/nbd0 或<br>
 ./nbd-2.9.15/output/bin/nbd-client bs=512 127.0.0.1 20000  hdfs:///tmp/testenv/testfs /dev/nbd0 
   * 测试nbd设备
     # sudo mkfs /dev/nbd0
     # sudo mount /dev/nbd0 /opt
     # do everything like a local device
----
----

== 高级用法 ==