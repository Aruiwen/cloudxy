#summary HLFS Architectural Design
=Hadoop DFS log structure filesystem design=
                                            -- Written by Kang Hua <kanghua151@gmail.com>, Translated by Harry Wei <harryxiyou@gmail.com>. 

==Background introduction==
   HLFS(Hadoop DFS Log FileSystem) is used to provide virtual disk for elastic cloud platform (The same as Amazon's EBS) and backend storage service. It needs to satisfy some characters including usability, high-performance, random reading and writing, fast fault recovery, data snapshots, rollback and so on.

==Realization description==
     Hadoop DFS can be regarded as a reliable, extensible 'disk' at any time. However, it cannot be writtern randomly but append sequentially. So we cannot take it as our mirror storage system directly. Thus we should realize randomly W/R operations by appending logs with the help of thoughts about 'log structure filesystem'. 

==Descriptions Of Characteristics==
 * User mode file system -- Be different from the file-systems of standard kernel mode posix interfaces. HLFS is realized at user mode space and inserted into client-side as lib mode. It is unnecessary to achieve posix interface regulations, just some main semantics like pread/pwrite, etc.
 * Support randomly reading and writing -- File should support randomly reading and writing (according to file offset's location).
 * Support large file storage -- Single file needs to support over Tera Bits storage (The file here means the size disk of virtual machine).
 * Only support single file -- Under our usage condition, every virtual disk is an HLFS case, so the easiest design is we only provide one file (a disk in the virtual machine).
 * Client-orient consistency -- Virtual machine disk can only be attached to one virtual machine mirror at the moment, so we only need provide data consistency of virtual machine client.
 * Support snapshots and rollback -- Files can be taken snapshots freely and rollbacked in need(To host service virtual machine, snapshot and rollback is the most effective way to protect datas from pollution and damage).
 * Support multidata and multicopy -- More than one storage can ensure data safety and nearby access (Hadoop DFS helps us realize this).
 * Cluster system can be dynamically expanded  -- Storage nodes (PC servers) can be dynamically added without affecting normal service of cluster (Hadoop DFS helps us realize this). 
 * Cluster system can do fault switch implicitly  -- Faults of storage nodes do not affect service, and it is implicit to clients (Hadoop  DFS helps us realize this).


==Architectural Design==
HLFS disk data format is almost the same as normal file system (FFS-fast file system ), both are with the structures like indirect block, inode, directory ,etc. The differences are HLFS can separate disk(Here is Hadoop DFS's storage pool) into segments to manage, and current time has only one active segment(That is our segment at the logic end). These segments is connected with head to tail and make up a linear log. And any file's updating(data block, indirect block, inode, etc) will add a log to the tail of current segment. Obviously，the advantage of this action ensure the magnetic head's orderly movement and enhance the throughputs. The trouble is we have to recycle old datas(have been changed).If not, the disk will be full sooner or later. In summary, our basic ideas of architectural design are that provide dependable and distributed storage image with the help of Hadoop DFS and finish LFS(Log Structured FileSystem) stuffs based on Hadoop DFS.


==HLFS log's create and index==
    Log is the basic unit for our datas' persistence. In fact, to the need of synchro writing, we make a new log by each writing action, which has different size each time. 
    The contents of log include data block, metadata(indirect block,etc) information, and metadata's meta-information(inode). In this way, we can finish indexing one information correctly.

===LOG create===
 * Any change of files or directories should write into a log with following portions. And they must write in-order semantics -- The aim is to recovery datas consistently if has any crashes.   
 # Any change or new data block (Data-block is smallest operation unit; configurable; size is 8KB or bigger)
 # Indirect block update (Also named as meta-data block, is inode's 2/3/4 inodex data blocks)
 # Inode update (Each inode is corresponding a file. If we only afford one file, we need only one inode)
 # Inode map update (Sinal file has only one Inode map entry) 
 * Log's constructure: *A (data）| B (meta-data block log) | C (inode log) | D(inode_map log)*

===Data Index===
  Read file's lastest datas: Firstly, find the lastest inode map entry. Secondly, find the corresponding inode. Thirdly, find file's logic address's physical address of the datablock(segment number and segment offset). At last, read datas.
  The latest Inode map entry's location should write into checkpoint file(see fault recovery for details). HLFS read them when it is initial; If it is running, Inode map entry structure should stay in RAM.
 * NOTE: Data block(Can be configured) is changable, like 8KB. If change size less than DB size, it will read a DB and change DB and take append opration at last.

===Space management - Segment===
 * Split into Segments -- In order to manage and recycle space, we have to split space into segments; Each segment size should not be stationary, and it has no hard regulations for the segment size.
  ** Each segment is mapped as a Hadoop DFS file, 64 M (configurable); The name of a segment file should be segno.seg, which the 'segno' increases by 0;
  ** Data block storage address (storage address) is 64 bits. Front parts are segment numbers and left parts are offset of a segment.(If segment size is 64MB, that is to say front parts are 26 bits).

  * Segment recycle -- (Segment Clean)It will bring much old datas when we append logs in sequence. So we have to design a recycle mechanism for old ones. In general, the recycle thoughts are all the data blocks' traversal in a segment, which will find the if the current inode index blocks directed to it. If not we we will remove this one. If one segment has a little usage data blocks, we will take the way, 'copy and remove' -- append a new log with the usage datas and remove that segment. 

We can divide the recycle to two steps:
  # Calculate the usage ones in a segment (Get the active data blocks in one segment);
  # Do the remove or 'copy and remove' action if the counts of active data blocks less than horizon(Configurable).
  * "Calculate segment usage" can be realized by a tool, which storage the special usage datas into file segment_usage.txt. We can take the way 'Pull mode'(Get the segment to local) from the pc of hlfs client to execute the task calculate segment usage stuffs; Also take another one 'Push mode'(map/reduce way for nearby calculations) to execute segment usage conditions in parallel.
  * "Segment Recycle" stuffs can be done by the only thread for hlfs so it can avoid change inode datas in parallel. Recycle is a low level task so writing jobs will be done at first. When there is no writing tasks we will carry out recycle actions.  
 
===Snapshot realize===
Log structure filesystem is born with snapshot function. Each log(Not recycled) we write can be a nature snaposhot. That is to say, we can recover that time's datas, which need only load the snapshot's inode. So it can rollback to any time's. But we will not keep all the datas. We suggest users should give a checkpoint for their key datas, which will get a permanent snapshot(contains inode address, take snapshot time, snapshot name) that is recorded into the file named checkpoint.txt. The inode has a snapshot will not be recycled. 

==The files HLFS need(All created by appending)== 
 * File SEGMENT -- The main data is storaged here, see 'Space management - Segment' for details. 
 * File Superblock -- Record HLFS's configure datas, like data block size, segment size, etc. If it is set, it will be unchangeable. See sources of tool mkfs.hlfs for details.
 * File Segments_usage.txt -- Record each segment's usage condition. Every line is only for one segment.
 * File Segments_delmark.txt -- Record removed segments information. Once a segment is removed, it will write down in this file.
 * File snapshot.txt -- Record snapshots information, which are different time's log records. 
 * File alive_snapshot.txt -- Record the current time's active snapshot, it is useful for our tree snapshots usage. See http://code.google.com/p/cloudxy/wiki/HlfsSnapshotDesign for details.

===The key APIS=== 
The key APIS have following characters:
 # C-Style APIS; 
 # Thread-Safe (Because each accessor maintain his own HLFS_CTRL context)
 # The File-System of interfaces (HLFS has only one file, so no any concepts about file name)

 * HLFS_CTRL*init_hlfs(const char*uri)
 * int deinit_hlfs(HLFS_CTRL*ctrl)
 * int hlfs_stat  (HLFS_CTRL*ctrl,HLFS_STAT_T*stat)
 * int hlfs_open  (HLFS_CTRL*ctrl,int flag)
 * int hlfs_close (HLFS_CTRL*ctrl)
 * int hlfs_read  (HLFS_CTRL*ctrl,char*read_buf,uint32_t read_len,uint64_t pos)
 * int hlfs_write (HLFS_CTRL*ctrl,char*write_buf,uint32_t write_len,uint64_t pos)     

==Some shortages about our project==
 # the code in the memory usage without refinement, many places is wasted (and possibly even a small amount of memory leak). So as far as possible loose     the memory.when running in the dom(),please keep the memory 1G at least.(512M is so small)
 # The link management doesn't been pooled.It exist the problem that open repeatedly.The connection is that link to the back-end storage (the connection handle of hdfs).This action that open and close repeatedly will waste many time on the network.So we will inprove the action in the future.
 # For the clean segment operations, it exist that the segment you want to delete  what is being accessed.Now we should have use reference technology to protect,but we use the simple locking:locking when read or write , and delete file when neither opening operating or writing operating.We will improve this.
 # If you don't call close when you close file ,you can't find the file in others connection context.The bug will bring a problem(note:you don't although see the file in namespace but you can see in hadoop fs -tail.Becouse the date what read from inputstream is not been submitted to the name node,it store in the date node).

{{{
Particularly Thanks 
Speaking of the origin of HLFS 's development，
we have to mention of the Taobaocom一YangZhiFeng and his a few friends whom we have never met.
In Ali Cloud they have referred to public paper of log-structured file system to development a standard log structrue filesystem (XuanYuan System),
the original idea for virtual machine storage,but unfortunately for a variety of reasons final project premature death, and not be finally adopted. 
I was lucky enough to have seen their documents and code, although at that time my 
comprehension to log structure filesystem and virtual machine mirror storage requirements seemed to look shallow,
but I also thought that it's a good choice to combined log structure filesytem  with HDFS一一 this  additional 
distributed storage system for the virtual machine mirror of the storage (so I had consult to ZhiFeng 
for many times and learned its realization .His superb technology and professional quality achieved people' admiration).
As for my further research for log structure filesytem and virtual machine mirror IO ,certainly more important is that the 
first abundant work of ZhiFeng proved this scheme is feasible,so let me believe in the virtual machine mirror storage characteristics 
aiming a log structrue block mirror storage system is really worth to try. 
So in the virtual machine mirror access features,I began to implement a log structure block systemt that aim at block, what is now HLFS.
The log structure block systemt ,compared with standard will be achieved more succinct (because no file structure),
its snapshots, merge scheme should be more succinct and efficient, optimize the room more.
But meanwhile I must say sorry to them for that HLFS' early release took no mention of ZhiFeng and his team.
Until today I get their agreement,so一一 special thanks to them for the years of groundbreaking to try.
If without their prospective jobs, HLFS would have gone a lot of curved road.
I just now asked ZhiFeng for the names of his friends (as follows) which I have never seen .
Thank them sinserely again, and hope they can  make more suggestions and help to cloudxy ,
they are:
      Name             Mailbox
    * YangZhiFeng   ： yangzhifeng83@gmail.com
    * DongChao      ： dongchao51@hotmail.com
    * ZhengWenJing  ： zhengwenjingster@gmail.com
    * DengYan       ： dengyan@act.buaa.edu.cn
}}}

You can also refer to the initial paper about 'log structure filesystem' in the Downloads list in the top of this page.
----------------------------
Translated By Harry Wei <harryxiyou@gmail.com>, Dai Jinwei <daijiwei41@gmail.com>，Zhang Jingpeng, Feng Siyu. 2012，3,2