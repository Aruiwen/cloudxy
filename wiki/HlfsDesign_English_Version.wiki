#summary HLFS Frame Design
=Hadoop DFS log structure filesystem design=
                                            -- Written by Kang Hua, Translated by Harry Wei, etc. 

==Background introduction==
   HLFS(Hadoop DFS Log FileSystem) is used to provide virtual disk for elastic cloud platform (The same as Amazon's EBS) and backend storage service. It needs to satisfy some characters including usability, high-performance, random reading and writing, fast fault recovery, data snapshots, rollback and so on.

==Realization description==
     Hadoop DFS can be regarded as a reliable, extensible 'disk' at any time. However, it cannot be writtern randomly but append sequentially. So we cannot take it as our mirror storage system directly. Thus we should realize randomly W/R operations by appending logs with the help of thoughts about 'log structure filesystem'. 

==Descriptions Of Characteristics==
 * User mode file system ------- different to standard kernel mode posix interface file system. HLFS is realized at user mode and implanted into client-side as lib. It is unnecessary to realize posix interface standard, realizing pread/pwrite is ok.
 * Supporting random reading and writing ------- file supports random reading and writing (according to offset  location ).
 * Supporting large files storage ------- single file needs to support over T data storage (the file means the disk of virtual machine).
 * Only supporting single file ------ every virtual disk corresponds an HLFS case, so the easiest design only supports one file (corresponding a disk in a virtual machine).
 * Client  - orient ------ virtual machine disk can only be attached to one virtual machine mirror, so we need to keep the data same of virtual machine client.
 * Supporting snapshot and rollback ------ we can do snapshot and rollback on a file (to host service virtual machine, snapshot and rollback is the most effective way to protect data from pollution and damage).
 * Supporting multidata and multicopy  -------  more than one storage can ensure data safety and  nearly visit (hadoop helps us realize this).
 * Cluster system can do dynamic expansion  ------- storage nodes (PC servers ) can do dynamic expansion without affecting  normal service of cluster (hadoop helps us realize this). 
 * Cluster system can do fault switch limpidly  -------- fault of storage nodes does not affect service, and it is limpid to clients (hadoop helps us realize this).


==Design summary=
      Disk data format of HLFS is almost the same with normal file system
(FFS-fast file system ), they both have the aid of structures like indirect block,  inode, directory. The difference is that LFS separates disk into segment to manage them, and there is only one active segment. These segments is connected head to tail and make up a linear log. Any file updating will be added to the tail of log. The advantage of this action is ensuring order mobile of disk head and enhancing the throughput. The trouble is we need to recover old data or the disk will be full sooner or later. To sum up, the basic ideas of our design is that realizing LFS on the reliable and distributed medium provided by hadoop dfs.


===HLFS LOG 创建和检索===
     LOG 是我们数据持久化的一个基本写入单位,对于写透需求来说，实际上每次写入动作都会产生一个新的LOG，而每次的LOG大小不尽相同。
LOG的内容显然必须包含被写入的数据块，还需要包含对应的元数据（索引块等）信息，以及元数据的元信息（inode)，这样才能完成对一个信息的索引。

====LOG创建====
    任何文件或者目录的修改LFS都需要向log中写入如下几部分信息，而且要求严格“按照顺序写入（in-order semantics）”—— 其目的是为了崩溃时能尽可能恢复数据一致性。
 # 任何修改或者新数据块  （数据块是数据实际操作的最小粒度；可配置；大小为8196字节或者更大）
 # Indirect block 更新   （也叫做meta-data block ，是inode中的2/3/4级索引块数据）
 # Inode          更新   （每个inode对应一个文件，如果只支持单一文件，则只用一个inode)
 # Inode map      更新    ( 单一文件则只有一个映射项）
 LOG 的布局为 ： *A (data）| B (meta-data block log) | C (inode log) | D(inode_map log)*。
====数据检索====
  读取文件最新数据时：需要通过找到最新的inode map位置，再进而找到所需文件对应inode，再进而找到文件逻辑地址对应的数据块的物理地址（段号+offset)，再进而读取数据。
  最新Inode map位置按理应记录在checkpoint文件中（见错误恢复部分），HDFS初始化加载时读入；如果运行中则该inode map 驻留于内存数据结构中。
  * 注意，文件块大小是可变的（可配置），比如8k。对于不足一个块的修改，一定会伴随先读出完整块再修改，再追加这一过程。

===Space management===
 * In order to control space management and the purpose of the recovery, we have to storage space for segmentation, each segment size does not need fixed, and specific size and no hard and fast rules;
  ** Each section of the HLFS mapping a Hadoop Dfs documents, such as size for 64 M (configurable); Segment file name format for segno. Seg, of which segno increasing starting from 0;
  ** Data block storage address (storage address) for 64, a front for the file number segment, the rear segment for file within offset-such as a period of size is 64 M, the tail need 26 ;

 * Period of recovery-(segment clean) file system log structure order additional behavior will bring lots of old data, and therefore must be something old data recovery mechanism. Recovery mechanism for general need to traverse section of the document data block, check the current inode index blocks of the address is a pointer to it, if not show is this block is old data can give up, if a segment of the data block is all old pieces of data is the period of file can be recycled (from HDFS removed). Another when paragraph data block rarely available, may also take the copy and remove way--will the old data data block the initiative to log form new auxiliary wrote paragraph, so that the original segment of the data block all become will block, then delete it again.
In the realization of the HLFS, period of recovery process into row:
 # The first step for calculation of the use of statistical (statistics section of the current and how much data blocks active);
 # The second part to the active piece of less than horizon of the section (horizontal line can set) executive delete or copy and remove actions to recovery space.
 * "Period of the use of statistical" by external tools program realization, produce the period of use of the count stored in segment_usage. TXT. We can HLFS from client's machine to "pull mode" (will read to local for the period of statistical task; Also can use "push mode" (map/reduce calculation way near) and implement period of statistical task.
 * "Period of recovery" work is the only written by HLFS threads to execute, thus to avoid metadata (inode) and modification of the problems, and recycling as a low priority task, will first make way for normal written to the task, and only when the current no writing task will begin to carry out the period of recovery task.
 
===Snapshot realize===
  In the log structure filesystem snapshot is implemented on the characteristics of congenital have. 
  Every time we write log (anyone without being recycled log) can serve as a snapshot point, also can restore that at the time of data, and the specific way is very simple, need to be loaded in the moment that the snapshot log inode can. So in principle of data can be rolled back we to any a written to the moment. However, we generally will not retain all the data, because this proposal for their users consider important data state do a mark so that you can get a permanent snapshot, the permanent snapshot will be written to cheakpoint. TXT file (record time inode address the snapshot, time, name can). This is the inode snapshot information was not recycling.


===The API of achieving has three features=== 
 # C-style api; 
 # thread-safe (because every visitors maintain own HLFS_CTRL context)
 # the port like the file system (but it hasn't the concept of multi-file, so does not exist the concept of file names and)

 * HLFS_CTRL*init_hlfs(const char*uri)
 * int deinit_hlfs(HLFS_CTRL*ctrl)
 * int hlfs_stat (HLFS_CTRL*ctrl,HLFS_STAT_T*stat)
 * int hlfs_open (HLFS_CTRL*ctrl,int flag)
 * int hlfs_close (HLFS_CTRL*ctrl)
 * int hlfs_read (HLFS_CTRL*ctrl,char*read_buf,uint32_t read_len,uint64_t pos)
 * int hlfs_write (HLFS_CTRL*ctrl,char*write_buf,uint32_t write_len,uint64_t pos)     

==Some shortages about our project==
 # the code in the memory usage without refinement, many places is wasted (and possibly even a small amount of memory leak). So as far as possible loose     the memory.when running in the dom(),please keep the memory 1G at least.(512M is so small)
 # The link management doesn't been pooled.It exist the problem that open repeatedly.The connection is that link to the back-end storage (the connection handle of hdfs).This action that open and close repeatedly will waste many time on the network.So we will inprove the action in the future.
 # For the clean segment operations, it exist that the segment you want to delete  what is being accessed.Now we should have use reference technology to protect,but we use the simple locking:locking when read or write , and delete file when neither opening operating or writing operating.We will improve this.
 # If you don't call close when you close file ,you can't find the file in others connection context.The bug will bring a problem(note:you don't although see the file in namespace but you can see in hadoop fs -tail.Becouse the date what read from inputstream is not been submitted to the name node,it store in the date node).

{{{
Particularly Thanks 
Speaking of the origin of HLFS 's development，
we have to mention of the Taobaocom一YangZhiFeng and his a few friends whom we have never met.
In Ali Cloud they have referred to public paper of log-structured file system to development a standard log structrue filesystem (XuanYuan System),
the original idea for virtual machine storage,but unfortunately for a variety of reasons final project premature death, and not be finally adopted. 
I was lucky enough to have seen their documents and code, although at that time my 
comprehension to log structure filesystem and virtual machine mirror storage requirements seemed to look shallow,
but I also thought that it's a good choice to combined log structure filesytem  with HDFS一一 this  additional 
distributed storage system for the virtual machine mirror of the storage (so I had consult to ZhiFeng 
for many times and learned its realization .His superb technology and professional quality achieved people' admiration).
As for my further research for log structure filesytem and virtual machine mirror IO ,certainly more important is that the 
first abundant work of ZhiFeng proved this scheme is feasible,so let me believe in the virtual machine mirror storage characteristics 
aiming a log structrue block mirror storage system is really worth to try. 
So in the virtual machine mirror access features,I began to implement a log structure block systemt that aim at block, what is now HLFS.
The log structure block systemt ,compared with standard will be achieved more succinct (because no file structure),
its snapshots, merge scheme should be more succinct and efficient, optimize the room more.
But meanwhile I must say sorry to them for that HLFS' early release took no mention of ZhiFeng and his team.
Until today I get their agreement,so一一 special thanks to them for the years of groundbreaking to try.
If without their prospective jobs, HLFS would have gone a lot of curved road.
I just now asked ZhiFeng for the names of his friends (as follows) which I have never seen .
Thank them sinserely again, and hope they can  make more suggestions and help to cloudxy ,
they are:
      Name             Mailbox
    * YangZhiFeng   ： yangzhifeng83@gmail.com
    * DongChao      ： dongchao51@hotmail.com
    * ZhengWenJing  ： zhengwenjingster@gmail.com
    * DengYan       ： dengyan@act.buaa.edu.cn
}}}

You can also refer to the initial paper about 'log structure filesystem' in the Downloads list in the top of this page.
----------------------------
Translated By Harry Wei <harryxiyou@gmail.com>, Dai Jinwei <daijiwei41@gmail.com>，Zhang Jingpeng, Feng siyu, Dai Jinwei. 2012，3,2